# Auditory-Cortex-Modelling

## Auditory Cortex Model
Zulfiqar et al (2020) presented a computational model representing the dorsal and ventral streams of the auditory cortex. The model adapted a Wilson and Cowan firing-rate modeling framework to simulate spectral and temporal processing of sounds in these auditory streams. The model implements the peripheral audio processing stage by using a Gammatone filterbank to represent the tonotopic response of the cochlea. The cortical processing stage of the model has implemented two core (A1 and R) and two belt (Slow and Fast) areas. The Slow area represents the dorsal stream while the Fast area represents the ventral stream. Neuronal units in the Slow area are characterised by fine spectral tuning and slow temporal dynamics, while neuronal units in the Fast area are characterised by coarse spectral tuning and fast temporal dynamics. All four simulated area’s consist of 98 units, which are modeled by excitatory and inhibitory unit pairs. Output of the peripheral stage serves as tonotopic input to the excitatory units of A1 and R, while excitatory responses of A1 and R serve as tonotopic input for the Fast and Slow areas, respectively. 

## Research Aim
The investigation aims to evaluate whether sound classification using the Fast and Slow outputs of the Zulfiqar et al. (2020) model align with the respective roles of caudal and rostral areas in sound processing. Additionally, the amount of time required for Fast and Slow areas to most accurately classify sound will be compared to the average response time of 150 to 250 ms reported in literature.

## Methods
A set consisting of 288 sounds belonging 6 categories (speech, vocal sounds, animal sounds, music, tools and nature sounds) of equal size (n=48) will be used as the inputs to the Zulfiqar et al. (2020) model. The time-series contain 16000 data points representing excitatory response during a time-frame of 1s. Here, the sound classification abilities of the Fast and Slow areas in the model over time will be investigated. Support Vector Machines (SVM) will be used to classify the sounds. In order to simulate the recurrent processing of sound over time in the brain, a rolling-window classifier was chosen (Silva, Brandao, Castilho, & Pereira, 2015). The time-series model output will be divided into 20 sections representing 50 ms each, and each unit’s average response over each section will be calculated. The accuracy of the classifiers will be evaluated by using k-fold cross-validation. By inspecting the accuracy pattern of the classifier over time, the temporal aspect of sound recognition will be evaluated. Comparing the accuracy for each of the six sound categories between the two belt areas, allows both ventral and dorsal streams to be evaluated in terms of how well they classify sounds.
